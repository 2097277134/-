{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "torchvision\n",
    "matplotlib\n",
    "\"\"\"\n",
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "\n",
    "\n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    "angle=270\n",
    "# plot one example\n",
    "# print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "# print(train_data.train_labels.size())               # (60000)\n",
    "# print(train_data.train_data[0].size())\n",
    "# print(train_data.train_data[0])\n",
    "\n",
    "\n",
    "# img1 = transforms.RandomRotation()(train_data.train_data)\n",
    "# img2 = torchvision.transforms.RandomHorizontalFlip()(train_data.train_data[0])\n",
    "# img3 = torchvision.transforms.RandomHorizontalFlip()(train_data.train_data[0])\n",
    "# plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "# plt.subplot(2,2,1),plt.imshow(train_data.train_data[0].numpy()),plt.title(\"原图\")\n",
    "# plt.subplot(2,2,2),plt.imshow(img1.numpy()),plt.title(\"转换后的图1\")\n",
    "# print(img1.size)\n",
    "\n",
    "# plt.subplot(2,2,2),plt.imshow(img1[0].numpy()),plt.title(\"1\")\n",
    "# plt.subplot(2,2,3),plt.imshow(img2.numpy()),plt.title(\"2\")\n",
    "# plt.subplot(2,2,4),plt.imshow(img3.numpy()),plt.title(\"3\")\n",
    "# plt.title('%i' % train_data.train_labels[0])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"随机裁剪后的大小:\",data1.size)\n",
    "# data2 = transforms.RandomResizedCrop(224)(img)\n",
    "# data3 = transforms.RandomResizedCrop(224)(img)\n",
    "\n",
    "# plt.subplot(2,2,1),plt.imshow(img),plt.title(\"原图\")\n",
    "# plt.subplot(2,2,2),plt.imshow(data1),plt.title(\"转换后的图1\")\n",
    "# plt.subplot(2,2,3),plt.imshow(data2),plt.title(\"转换后的图2\")\n",
    "# plt.subplot(2,2,4),plt.imshow(data3),plt.title(\"转换后的图3\")\n",
    "# plt.show()\n",
    "# 数据加载器，用于在训练中简单地进行小批量返回，图像批量形状将为（50，1，28，28）\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# print(train_loader[0])\n",
    "# train_data.train_data=transforms.RandomRotation(100)(train_data.train_data)\n",
    "# 采集2000个样本以加快测试速度\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test=transforms.RandomRotation(angle)(test_data.test_data)\n",
    "\n",
    "test_x = torch.unsqueeze(test, dim=1).type(torch.FloatTensor)[:2000].cuda()/255.   # Tensor on GPU  # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000].cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.2845 | test accuracy: 0.86\n",
      "Epoch:  0 | train loss: 0.2011 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.3570 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2322 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.2672 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2163 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.1796 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.3700 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.3066 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.4031 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1543 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.2217 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.1378 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.2556 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.3225 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.0840 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1645 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.1847 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.4769 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.4358 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1536 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.1541 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2704 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.2364 | test accuracy: 0.91\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], device='cuda:0') prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "cnn.cuda()      # Moves all model parameters and buffers to the GPU.\n",
    "# print(cnn)  # net architecture\n",
    "\n",
    "cnn.load_state_dict(torch.load('net_params.pkl'))\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "try: from sklearn.manifold import TSNE; HAS_SK = False\n",
    "except: HAS_SK = False; print('Please install sklearn for layer visualization')\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "        x=transforms.RandomRotation(angle)(x)\n",
    "        b_x = x.cuda()    # Tensor on GPU\n",
    "        b_y = y.cuda()    # Tensor on GPU\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            # !!!!!!!! Change in here !!!!!!!!! #\n",
    "            pred_y = torch.max(test_output, 1)[1].cuda().data  # move the computation in GPU\n",
    "            # pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "            # accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            # print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "            if HAS_SK:\n",
    "                # Visualization of trained flatten layer (T-SNE)\n",
    "                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "                plot_only = 500\n",
    "                low_dim_embs = tsne.fit_transform(last_layer.data.cpu().numpy()[:plot_only, :])\n",
    "                labels = test_y.cpu().numpy()[:plot_only]\n",
    "                plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n",
    "\n",
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "# pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "pred_y = torch.max(test_output, 1)[1].cuda().data # move the computation in GPU\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].cpu().numpy(), 'real number')\n",
    "\n",
    "torch.save(cnn.state_dict(), 'net_params.pkl')   # 只保存网络中的参数 (速度快, 占内存少)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x49 and 1568x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m test_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(test, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)[:\u001b[39m2000\u001b[39m]\u001b[39m.\u001b[39mcuda()\u001b[39m/\u001b[39m\u001b[39m255.\u001b[39m   \u001b[39m# Tensor on GPU  # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m test_y \u001b[39m=\u001b[39m test_data\u001b[39m.\u001b[39mtest_labels[:\u001b[39m2000\u001b[39m]\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> 49\u001b[0m output \u001b[39m=\u001b[39m cnn(test_x[\u001b[39m0\u001b[39;49m])[\u001b[39m0\u001b[39m]  \n\u001b[0;32m     51\u001b[0m pred_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(output, \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcuda()\u001b[39m.\u001b[39mdata \u001b[39m# move the computation in GPU\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39mprint\u001b[39m(pred_y)\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[28], line 26\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n\u001b[0;32m     25\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)           \u001b[39m# flatten the output of conv2 to (batch_size, 32 * 7 * 7)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout(x)\n\u001b[0;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m output, x\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x49 and 1568x10)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "torchvision\n",
    "matplotlib\n",
    "\"\"\"\n",
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    "angle=270\n",
    "# 数据加载器，用于在训练中简单地进行小批量返回，图像批量形状将为（50，1，28，28）\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 采集2000个样本以加快测试速度\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "test=transforms.RandomRotation(angle)(test_data.test_data)\n",
    "\n",
    "test_x = torch.unsqueeze(test, dim=1).type(torch.FloatTensor)[:2000].cuda()/255.   # Tensor on GPU  # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000].cuda()\n",
    "output = cnn(test_x[0])[0]  \n",
    "\n",
    "pred_y = torch.max(output, 1)[1].cuda().data # move the computation in GPU\n",
    "print(pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 117)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:117\u001b[1;36m\u001b[0m\n\u001b[1;33m    print('测试结果:{}/{}'.format(correct, total))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from digit_recog import Net\n",
    "from digit_recog_mydataset import MyDataset\n",
    " \n",
    " \n",
    "# 读取已保存的模型\n",
    "def getmodel(pth, net):\n",
    "    state_filepath = pth\n",
    "    if os.path.exists(state_filepath):\n",
    "        # 加载参数\n",
    "nn_state = torch.load(state_filepath)\n",
    "        # 加载模型\n",
    "net.load_state_dict(nn_state)\n",
    "        # 拷贝一份\n",
    "return copy.deepcopy(nn_state)\n",
    "    else:\n",
    "        return net.state_dict()\n",
    " \n",
    " \n",
    "# 构建数据集\n",
    "def getdataset(batch_size):\n",
    "    # 定义数据预处理方式\n",
    "transform = transforms.ToTensor()\n",
    " \n",
    "    # 定义训练数据集\n",
    "trainset = tv.datasets.MNIST(\n",
    "        root='./data/',\n",
    "train=True,\n",
    "download=True,\n",
    "transform=transform)\n",
    " \n",
    "    # 去掉注释，加入自己的数据集\n",
    "# trainset += MyDataset(os.path.abspath(\"./data/myimages/\"), 'train.txt', transform=transform)\n",
    " \n",
    "    # 定义训练批处理数据\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "batch_size=batch_size,\n",
    "shuffle=True,\n",
    ")\n",
    " \n",
    "    # 定义测试数据集\n",
    "testset = tv.datasets.MNIST(\n",
    "        root='./data/',\n",
    "train=False,\n",
    "download=True,\n",
    "transform=transform)\n",
    " \n",
    "    # 去掉注释，加入自己的数据集\n",
    "# testset += MyDataset(os.path.abspath(\"./data/myimages/\"), 'test.txt', transform=transform)\n",
    " \n",
    "    # 定义测试批处理数据\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "batch_size=batch_size,\n",
    "shuffle=False,\n",
    ")\n",
    " \n",
    "    return trainloader, testloader\n",
    " \n",
    " \n",
    "# 训练\n",
    "def training(device, net, model, dataset_loader, epochs, criterion, optimizer, save_model_path):\n",
    "    trainloader, testloader = dataset_loader\n",
    "    # 最佳模型\n",
    "best_model_wts = model\n",
    "    # 最好分数\n",
    "best_acc = 0.0\n",
    "# 计时\n",
    "since = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "# 训练数据集\n",
    "for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # 梯度清零，避免带入下一轮累加\n",
    "optimizer.zero_grad()\n",
    "            # 神经网络运算\n",
    "outputs = net(inputs)\n",
    "            # 损失值\n",
    "loss = criterion(outputs, labels)\n",
    "            # 损失值反向传播\n",
    "loss.backward()\n",
    "            # 执行优化\n",
    "optimizer.step()\n",
    "            # 损失值汇总\n",
    "sum_loss += loss.item()\n",
    "            # 每训练完100条数据就显示一下损失值\n",
    "if i % 100 == 99:\n",
    "                print('[%d, %d] loss: %.03f'\n",
    "% (epoch + 1, i + 1, sum_loss / 100))\n",
    "                sum_loss = 0.0\n",
    "# 每训练完一轮测试一下准确率\n",
    "with torch.no_grad():\n",
    "            correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                # 取得分最高的\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "                # print(labels)\n",
    "                # print(torch.nn.Softmax(dim=1)(outputs.data).detach().numpy()[0])\n",
    "                # print(torch.nn.functional.normalize(outputs.data).detach().numpy()[0])\n",
    "total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    " \n",
    "            print('测试结果:{}/{}'.format(correct, total))\n",
    "            epoch_acc = correct.double() / total\n",
    "            print('当前分数:{} 最高分数:{}'.format(epoch_acc, best_acc))\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(net.state_dict())\n",
    "            print('第%d轮的识别准确率为：%d%%' % (epoch + 1, (100 * correct / total)))\n",
    " \n",
    "    time_elapsed = time.time() - since\n",
    "    print('训练完成于 {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('最高分数: {:4f}'.format(best_acc))\n",
    "    # 保存训练模型\n",
    "if save_model_path is not None:\n",
    "        save_state_path = os.path.join('model/', 'net.pth')\n",
    "        torch.save(best_model_wts, save_state_path)\n",
    " \n",
    " \n",
    "# 基于cpu还是gpu\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NET = Net().to(DEVICE)\n",
    "# 超参数设置\n",
    "EPOCHS = 8# 训练多少轮\n",
    "BATCH_SIZE = 64  # 数据集批处理数量 64\n",
    "LR = 0.001  # 学习率\n",
    " \n",
    "# 交叉熵损失函数，通常用于多分类问题上\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "# OPTIMIZER = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "OPTIMIZER = optim.Adam(NET.parameters(), lr=LR)\n",
    "MODEL = getmodel(os.path.join('model/', 'net.pth'), NET)\n",
    "training(DEVICE, NET, MODEL, getdataset(BATCH_SIZE), 1, CRITERION, OPTIMIZER, os.path.join('model/', 'net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3961 | test accuracy: 0.11\n",
      "Epoch:  0 | train loss: 1.6933 | test accuracy: 0.20\n",
      "Epoch:  0 | train loss: 1.4578 | test accuracy: 0.17\n",
      "Epoch:  0 | train loss: 1.3925 | test accuracy: 0.46\n",
      "Epoch:  0 | train loss: 1.0747 | test accuracy: 0.45\n",
      "Epoch:  0 | train loss: 0.8234 | test accuracy: 0.44\n",
      "Epoch:  0 | train loss: 0.7360 | test accuracy: 0.59\n",
      "Epoch:  0 | train loss: 1.1119 | test accuracy: 0.50\n",
      "Epoch:  0 | train loss: 0.8792 | test accuracy: 0.46\n",
      "Epoch:  0 | train loss: 0.8602 | test accuracy: 0.63\n",
      "Epoch:  0 | train loss: 0.5425 | test accuracy: 0.71\n",
      "Epoch:  0 | train loss: 0.8942 | test accuracy: 0.50\n",
      "Epoch:  0 | train loss: 0.6891 | test accuracy: 0.65\n",
      "Epoch:  0 | train loss: 0.6167 | test accuracy: 0.63\n",
      "Epoch:  0 | train loss: 0.5870 | test accuracy: 0.63\n",
      "Epoch:  0 | train loss: 0.6215 | test accuracy: 0.70\n",
      "Epoch:  0 | train loss: 0.6699 | test accuracy: 0.66\n",
      "Epoch:  0 | train loss: 0.5001 | test accuracy: 0.61\n",
      "Epoch:  0 | train loss: 0.5575 | test accuracy: 0.66\n",
      "Epoch:  0 | train loss: 0.6123 | test accuracy: 0.60\n",
      "Epoch:  0 | train loss: 1.0448 | test accuracy: 0.65\n",
      "Epoch:  0 | train loss: 0.6812 | test accuracy: 0.70\n",
      "Epoch:  0 | train loss: 0.6300 | test accuracy: 0.50\n",
      "Epoch:  0 | train loss: 0.5924 | test accuracy: 0.71\n",
      "Epoch:  1 | train loss: 0.7231 | test accuracy: 0.60\n",
      "Epoch:  1 | train loss: 0.4817 | test accuracy: 0.67\n",
      "Epoch:  1 | train loss: 0.5920 | test accuracy: 0.67\n",
      "Epoch:  1 | train loss: 0.5649 | test accuracy: 0.65\n",
      "Epoch:  1 | train loss: 0.5952 | test accuracy: 0.58\n",
      "Epoch:  1 | train loss: 0.3247 | test accuracy: 0.62\n",
      "Epoch:  1 | train loss: 0.5681 | test accuracy: 0.69\n",
      "Epoch:  1 | train loss: 0.4109 | test accuracy: 0.71\n",
      "Epoch:  1 | train loss: 0.4257 | test accuracy: 0.64\n",
      "Epoch:  1 | train loss: 0.3838 | test accuracy: 0.69\n",
      "Epoch:  1 | train loss: 0.4277 | test accuracy: 0.57\n",
      "Epoch:  1 | train loss: 0.5474 | test accuracy: 0.66\n",
      "Epoch:  1 | train loss: 0.2290 | test accuracy: 0.75\n",
      "Epoch:  1 | train loss: 0.5143 | test accuracy: 0.60\n",
      "Epoch:  1 | train loss: 0.2840 | test accuracy: 0.58\n",
      "Epoch:  1 | train loss: 0.2767 | test accuracy: 0.60\n",
      "Epoch:  1 | train loss: 0.5083 | test accuracy: 0.73\n",
      "Epoch:  1 | train loss: 0.7785 | test accuracy: 0.53\n",
      "Epoch:  1 | train loss: 0.5495 | test accuracy: 0.55\n",
      "Epoch:  1 | train loss: 0.3701 | test accuracy: 0.47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 122\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39m# training and testing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCH):\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m step, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):   \u001b[39m# gives batch data, normalize x when iterate train_loader\u001b[39;00m\n\u001b[0;32m    123\u001b[0m         b_x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mcuda()    \u001b[39m# Tensor on GPU\u001b[39;00m\n\u001b[0;32m    124\u001b[0m         b_y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mcuda()    \u001b[39m# Tensor on GPU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[1;32mc:\\Users\\20972\\.conda\\envs\\pytorch_GPU\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(mean, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(std, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[39mif\u001b[39;00m (std \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49many():\n\u001b[0;32m    923\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstd evaluated to zero after conversion to \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m, leading to division by zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "torchvision\n",
    "matplotlib\n",
    "\"\"\"\n",
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 10               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "train_transform = transforms.Compose([\n",
    "                                transforms.RandomAffine(degrees = 0,translate=(0.1, 0.1)),#对照片进行随机平移\n",
    "                                transforms.RandomRotation((-180,180)),        #随机旋转\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.RandomAffine(degrees = 0,translate=(0.1, 0.1)),#对照片进行随机平移\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.RandomRotation((-180,180)),        #随机旋转\n",
    "                                    transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "\n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=train_transform,    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# pick 2000 samples to speed up testing\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False,transform=test_transform)\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000].cuda()/255.   # Tensor on GPU  # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000].cuda()\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=5,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "cnn.cuda()      # Moves all model parameters and buffers to the GPU.\n",
    "# print(cnn)  # net architecture\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "\n",
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "try: from sklearn.manifold import TSNE; HAS_SK = False\n",
    "except: HAS_SK = False; print('Please install sklearn for layer visualization')\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "        b_x = x.cuda()    # Tensor on GPU\n",
    "        b_y = y.cuda()    # Tensor on GPU\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            # !!!!!!!! Change in here !!!!!!!!! #\n",
    "            pred_y = torch.max(test_output, 1)[1].cuda().data  # move the computation in GPU\n",
    "            # pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "            # accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "            # print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "            if HAS_SK:\n",
    "                # Visualization of trained flatten layer (T-SNE)\n",
    "                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "                plot_only = 500\n",
    "                low_dim_embs = tsne.fit_transform(last_layer.data.cpu().numpy()[:plot_only, :])\n",
    "                labels = test_y.cpu().numpy()[:plot_only]\n",
    "                plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n",
    "\n",
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "# pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "# !!!!!!!! Change in here !!!!!!!!! #\n",
    "pred_y = torch.max(test_output, 1)[1].cuda().data # move the computation in GPU\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].cpu().numpy(), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 97.570000 % [9757/10000]\n",
      "1 0.9757\n",
      "Accuracy on test set: 97.460000 % [9746/10000]\n",
      "2 0.9746\n",
      "Accuracy on test set: 97.590000 % [9759/10000]\n",
      "3 0.9759\n",
      "Accuracy on test set: 97.690000 % [9769/10000]\n",
      "4 0.9769\n",
      "Accuracy on test set: 97.430000 % [9743/10000]\n",
      "5 0.9743\n",
      "Accuracy on test set: 97.590000 % [9759/10000]\n",
      "6 0.9759\n",
      "Accuracy on test set: 97.510000 % [9751/10000]\n",
      "7 0.9751\n",
      "Epoch 00007: reducing learning rate of group 0 to 7.5000e-03.\n",
      "Accuracy on test set: 97.520000 % [9752/10000]\n",
      "8 0.9752\n",
      "Accuracy on test set: 97.620000 % [9762/10000]\n",
      "9 0.9762\n",
      "Accuracy on test set: 97.490000 % [9749/10000]\n",
      "10 0.9749\n",
      "Epoch 00010: reducing learning rate of group 0 to 3.7500e-03.\n",
      "Accuracy on test set: 97.620000 % [9762/10000]\n",
      "11 0.9762\n",
      "Accuracy on test set: 97.620000 % [9762/10000]\n",
      "12 0.9762\n",
      "Accuracy on test set: 97.680000 % [9768/10000]\n",
      "13 0.9768\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.8750e-03.\n",
      "Accuracy on test set: 97.680000 % [9768/10000]\n",
      "14 0.9768\n",
      "Accuracy on test set: 97.750000 % [9775/10000]\n",
      "15 0.9775\n",
      "Accuracy on test set: 97.780000 % [9778/10000]\n",
      "16 0.9778\n",
      "Accuracy on test set: 97.570000 % [9757/10000]\n",
      "17 0.9757\n",
      "Accuracy on test set: 97.640000 % [9764/10000]\n",
      "18 0.9764\n",
      "Accuracy on test set: 97.580000 % [9758/10000]\n",
      "19 0.9758\n",
      "Epoch 00019: reducing learning rate of group 0 to 9.3750e-04.\n",
      "Accuracy on test set: 97.860000 % [9786/10000]\n",
      "20 0.9786\n",
      "Accuracy on test set: 97.740000 % [9774/10000]\n",
      "21 0.9774\n",
      "Accuracy on test set: 98.010000 % [9801/10000]\n",
      "22 0.9801\n",
      "Accuracy on test set: 97.510000 % [9751/10000]\n",
      "23 0.9751\n",
      "Accuracy on test set: 97.670000 % [9767/10000]\n",
      "24 0.9767\n",
      "Accuracy on test set: 97.660000 % [9766/10000]\n",
      "25 0.9766\n",
      "Epoch 00025: reducing learning rate of group 0 to 4.6875e-04.\n",
      "Accuracy on test set: 97.600000 % [9760/10000]\n",
      "26 0.976\n",
      "Accuracy on test set: 97.670000 % [9767/10000]\n",
      "27 0.9767\n",
      "Accuracy on test set: 97.800000 % [9780/10000]\n",
      "28 0.978\n",
      "Epoch 00028: reducing learning rate of group 0 to 2.3437e-04.\n",
      "Accuracy on test set: 97.610000 % [9761/10000]\n",
      "29 0.9761\n",
      "Accuracy on test set: 97.680000 % [9768/10000]\n",
      "30 0.9768\n"
     ]
    }
   ],
   "source": [
    "train_epoch = []\n",
    "model_accuracy = []\n",
    "temp_acc = 0.0\n",
    "train_loss_val = []\n",
    "for epoch in range(30):\n",
    "    train(epoch)\n",
    "    acc = test()\n",
    "\n",
    "    print(epoch + 1,acc)\n",
    "    train_epoch.append(epoch)\n",
    "    model_accuracy.append(acc)\n",
    "    scheduler.step(acc)\n",
    "    torch.save(model.state_dict(), 'params\\\\'+str(epoch + 31)+'-'+str(acc)+'-'+'net_params.pt')   # 只保存网络中的参数 (速度快, 占内存少)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(train_epoch, model_accuracy)  # 传入列表，plt类用来画图\n",
    "plt.grid(linestyle=':')\n",
    "plt.ylabel('accuracy')  # 定义y坐标轴的名字\n",
    "plt.xlabel('epoch')  # 定义x坐标\n",
    "plt.show()  # 显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://mofanpy.com/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.4\n",
    "torchvision\n",
    "matplotlib\n",
    "\"\"\"\n",
    "# library\n",
    "# standard library\n",
    "import os\n",
    "\n",
    "# third-party library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 10               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = False\n",
    "train_transform = transforms.Compose([\n",
    "                                transforms.RandomAffine(degrees = 0,translate=(0.1, 0.1)),#对照片进行随机平移\n",
    "                                transforms.RandomRotation(90),        #随机旋转\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.RandomAffine(degrees = 0,translate=(0.1, 0.1)),#对照片进行随机平移\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.RandomRotation((-90,180)),        #随机旋转\n",
    "                                    transforms.Normalize((0.1307,),(0.3081,))])\n",
    "\n",
    "\n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=train_transform,    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,\n",
    "    \n",
    ")\n",
    "\n",
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())   \n",
    "i=10            # (60000)\n",
    "# while(i):\n",
    "#     i-=1\n",
    "#     plt.imshow(train_data.train_data[i].numpy(), cmap='gray')\n",
    "#     plt.title('%i' % train_data.train_labels[i])\n",
    "#     plt.show()\n",
    "k=1000\n",
    "fig, ax = plt.subplots(nrows=5, ncols=5, sharex='all', sharey='all')\n",
    "ax = ax.flatten()\n",
    "transforms.RandomRotation(90)(train_data.train_data)\n",
    "for i in range(25):\n",
    "    # img = transforms.RandomRotation(270)(train_data.train_data[i+k])\n",
    "    img=train_data.train_data[i+k].numpy()\n",
    "    ax[i].set_title(train_data.train_labels[i+k])\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
